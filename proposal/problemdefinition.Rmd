# The Problem

Analytical laboratories are a huge source of data. Unfortunately, laboratory data streams are often fragmented and not well curated. We reason that this is caused by the range of analytical instruments populating the lab---each with their own closed-sourced vendor-supplied data models and software suites for subsequent data processing, analysing, and diagnostics. These various data models, if accessible at all, are not easily integrated in a centralised data management infrastructure. This so-called "vendor lock-in" further prevents transparency of the workflow from raw to analysed data. Although low-level access to raw data and insights in workflows is not necessary for all scientist, it can be important for special purpose research questions, possibly sparking new innovations and discoveries. The fragmented, and partly obscured, nature of data streams from analytical laboratories further conflicts with data management principles, such as formalised in the Findable, Accessible, Interoperable, and Reusable (FAIR) data guiding principles [@Wilkinson2016], and have a negative impact on the reproducibility of science. Hence, facilitating better data management infrastructures for analytical labs is pertinent to open science, and is therefore a rewarding endeavour for future innovations and discoveries. In addition, FAIR data is conductive to an inclusive, connected worldwide academic community, providing opportunities for developing countries that do not have the same resources for data generation as wealthy countries.


 


<!-- 
Outlining the issue / weak point / problem to be solved by this proposal. This should be a compelling section that sets the reader up for the next section - the proposed solution!

It is important to cover:

 - [ ] What the problem is
 - [ ] Who it affects
 - [ ] Have there been previous attempts to resolve the problem
 - [ ] Why it should be tackled
-->


