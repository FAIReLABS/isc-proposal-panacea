# Requirements

The realisation of this package requires a collaborative environment that includes the potential users, and their specific requirements for processing analytical data, as well as developers and data scientist with expertise in a range of disciplines. In regards to development, we brought together a multi-disciplinary team, and consulted experts of data management and Natural Language Processing, and the integration of C++ and R.

<!-- 
An idea of what is required to make the project actually happen
-->

## People

The project team will try to form a comprehensive picture of the current state of data management practices in laboratories through direct interaction with lab-users. In addition, they take control in all steps of development, documentation and outreach of the package. Dedicated consultants have been contacted and their expertise is regarded as an essential aid for successful deployment of the plan.

The project lead (MS) is an Earth scientist with 10 years of experience in academic research, and he has worked in several analytical laboratory facilities (MfN Berlin, University of Leeds, and Utrecht University). He also has a solid basis in data-analysis and programming with R, and has started developing packages for the processing of isotope chemical data (see [point](https://martinschobben.github.io/point/)). Teaching and helping others to encode R solutions has been another of his passions, such as the development of [workshops](https://www.youtube.com/watch?v=r99jsChi4HU), and by founding of an R help desk at the UU ([uu-code-club](https://github.com/uu-code-club)).

JR, also a geoscientist, has expertise in data management (being the main maintainer and developer of Neptune; one of the largest paleontology database), data analysis (primarily in R and python), machine learning (see e. g. [a CNN-based radiolarian classifier](https://github.com/plannapus/RadiolarianClassifier)) and scientific software development (see e. g. [NSB_ADP_wx](http://github.com/plannapus/NSB_ADP_wx) or [Raritas](http://github.com/plannapus/Raritas); two pieces of software designed in particular for increasing data reproducibility and reusability in paleontology and stratigraphy). JR was also the organizer of a programming club at the MfN ([Mfn Code Clinic](http://github.com/plannapus/MfN-Code-Clinic)) from 2015 to 2018.

TR oversees the iRODS development team and handles code review, package management, documentation, and high level architecture design. He's interested in distributed systems, metadata, security, and open source software that accelerates science. TR holds a Ph.D. in Information Science from the University of North Carolina at Chapel Hill and has been working on iRODS since 2008. In his current role, he also provides management and oversight of the iRODS Consortium.

<!--
Who needs to be involved, what's the proposed structure, what will it take to get their involvement?
-->

## Processes

A prime controller in the initiation of the project is the report (and blog post) in the first two months (see, deliverable Months 1--2; Section \@ref(sec:Technical)), which tries to give an overview of existing data management infrastructures and common data models (i.e., instrument output) in analytical laboratory settings. Based on this deliverable, adoptions to the initial plan can be made. Specifically, it helps select what solution should be adopted for data selection and harmonisation. To foster an efficient start-up and continues collaboration, we adopt a strategy of publishing advancements in development at an early stage, so that testing and evaluation can begin as soon as possible. Feedback on these early developments is sought actively through our dedicated list of consultants, but also the community at large through Twitter and other channels. Throughout this process, we will make sure that the code of conduct, as outlined in Section \@ref(sec:Start), is adhered to.

<!-- 
What processes need to be put in place e.g. codes of conduct, regular ISC meetings, handover to the community at large?
-->

## Tools & Tech

For successful delivery of the package we need access to large quantities of raw data from various analytical instruments. We have secured access to data from Utrecht University and the MfN Berlin. GitHub is essential for the collaborative character of the work. No additional computing facilities are envisioned at the moment. 
<!--
What is going to be needed to deliver this project? 

Will cloud computing be used - if yes are there are necessary components that will be deciding factors between providers?

Are there tools or tech that don't exist that will be produced to facilitate the project?
-->

## Funding

We request \$xx,xxx for the salary of MS (project lead) for 0.5 ft working hours a week. This sum is based on the salary for a PostDoc in natural sciences, including the applicants years of experience. The remainder of working hours he will spend on developing and giving courses/workshops (see FAIReLABS; Section \@ref(sec:Start)) that entail best practices in data management, reproducible science and data science with R (see e.g., [PAGES workshop youtube](https://www.youtube.com/watch?v=r99jsChi4HU)). The latter activities are not include in the salary request. We also request \$x,xxx funding for the attendance of one conference (addressing a potential user-base).


<!-- 
[TO DO] THE GUIDANCE IS PRETTY UNCLEAR, ESP IN LIGHT OF GABOR'S PROPOSAL VS AWARD SIZE

-->

## Summary

Salary to support the project lead (MS) is requested. He will dedicate 0.5 ft (18 hours a week -  common under European labour laws) of his time to the development, documentation as well as outreach of the package.
<!--
A summary of the requirements that contextualises the costs
-->
